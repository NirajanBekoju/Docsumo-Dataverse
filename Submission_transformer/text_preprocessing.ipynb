{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxGdnaZPWunhVkUsHP7PHh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"NZj2b7RQ3_qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKt9mHAc3SOf","outputId":"4770b6e6-8d9b-4544-a69a-3862be213c15"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}],"source":["import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","stop_word_collection=set(stopwords.words('english'))"]},{"cell_type":"code","source":["from tqdm import tqdm\n","tqdm.pandas()"],"metadata":{"id":"fQmdEvzN3eKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"YmjXOTq13eC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_preprocess(text):\n","  # Changes to lower case\n","  text = text.lower()\n","\n","  # conver the - to white spaces\n","  # eg small-scale = small scale, two-dimension = two dimension\n","  text = text.replace(\"-\", \" \")\n","\n","  # Remove all punctuations\n","  text = ''.join(c for c in text if c not in string.punctuation)\n","\n","  # Remove all stop words\n","  text = ' '. join(word for word in text.split() if word not in stop_word_collection)\n","\n","  # Remove all numbers and words containing numbers\n","  text = re.sub(r'\\w*\\d\\w*', ' ', text).strip()\n","  \n","  # Lemmatization of all words\n","  text = [lemmatizer.lemmatize(word) for word in text.split()]\n","  text = ' '.join(text)\n","  return text"],"metadata":{"id":"IKFKy-Af3eAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_path = \"/content/drive/MyDrive/Colab Notebooks/DataVerse/train.csv\"\n","df = pd.read_csv(df_path)"],"metadata":{"id":"rNiFiLea3d9i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"text\"] = df.title.astype(\"str\") + df.abstract.astype(\"str\")"],"metadata":{"id":"5vD_qir93d7O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop([\"title\", \"abstract\"], axis = 1, inplace = True)"],"metadata":{"id":"fMku-fOl3xiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"text\"] = df[\"text\"].progress_apply(text_preprocess)"],"metadata":{"id":"c05FDp0Z3xbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_path = \"preprocessed_data.csv\"\n","df.to_csv(save_path, index = False)"],"metadata":{"id":"PPTDtJhc3xWT"},"execution_count":null,"outputs":[]}]}